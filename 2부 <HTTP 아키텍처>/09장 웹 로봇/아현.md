# 9. 웹 로봇
- 주식시장 서버에 매 분 HTTP GET 요청을 보내고, 여기서 얻은 데이터를 활용해 주가 추이 그래프를 생성하는 주식 그래프 로봇
- 월드 와이드 웹의 규모와 진화에 대한 통계 정보를 수집하는 웹 통계 조사 로봇
- 검색 데이터베이스를 만들기 위해 발견한 모든 문서를 수집하는 검색엔진 로봇
- 상품에 대한 가격 데이터베이스를 만들기 위해 온라인 쇼핑몰의 카탈로그에서 웹페이지를 수집하는 가격 비교 로봇
## 9.1 크롤러와 크롤링
### 9.1.1 어디에서 시작하는가: '루트 집합'
### 9.1.2 링크 추출과 상대 링크 정상화
### 9.1.3 순환 피하기
### 9.1.4 루프와 중복
### 9.1.5 빵 부스러기의 흔적
#### 트리와 해시 테이블
#### 느슨한 존재 비트맵
#### 체크포인트
#### 파티셔닝
### 9.1.6 별칭(alias)과 로봇 순환
### 9.1.7 URL 정규화하기
### 9.1.8 파일 시스템 링크 순환
### 9.1.9 동적 가상 웹 공간
### 9.1.10 루프와 중복 피하기
#### URL 정규화
#### 너비 우선 크롤링
#### 스로틀링
#### URL 크기 제한
#### URL/사이트 블랙리스트
#### 패턴 발견
#### 콘텐츠 지문(fingerprint)
#### 사람의 모니터링
## 9.2 로봇의 HTTP
### 9.2.1 요청 헤더 식별하기
#### User-Agent
#### From
#### Accept
#### Referer
### 9.2.2 가상 호스팅
### 9.2.3 조건부 요청
### 9.2.4 응답 다루기
#### 상태 코드
#### 엔터티
### 9.2.5 User-Agent 타기팅
## 9.3 부적절하게 동작하는 로봇들
#### 폭주하는 로봇
#### 오래된 URL
#### 길고 잘못된 URL
#### 호기심이 지나친 로봇
#### 동적 게이트웨이 접근
## 9.4 로봇 차단하기
### 9.4.1 로봇 차단 표준
### 9.4.2 웹 사이트와 robots.txt 파일들
### 9.4.3 robots.txt 파일 포맷
### 9.4.4 그 외에 알아둘 점
### 9.4.5 robots.txt의 캐싱과 만료
### 9.4.6 로봇 차단 펄 코드
### 9.4.7 HTML 로봇 제어 META 태그
## 9.5 로봇 에티켓
## 9.6 검색엔진
### 9.6.1 넓게 생각하라
### 9.6.2 현대적인 검색엔진의 아키텍처
### 9.6.3 풀 텍스트 색인
### 9.6.4 질의 보내기
### 9.6.5 검색 결과를 정렬하고 보여주기
### 9.6.6 스푸핑
## 9.7 추가 정보
